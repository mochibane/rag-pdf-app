# ğŸ“˜ RAG PDF App (Streamlit)

Application **Question/RÃ©ponse sur PDF** basÃ©e sur **LLMs OpenAI**, dÃ©veloppÃ©e avec **Streamlit**.  
Elle permet de :  
- Importer un PDF et crÃ©er un index local (RAG)  
- Poser des questions en langage naturel sur le PDF  
- GÃ©nÃ©rer un rÃ©sumÃ© du PDF  
- Mettre en Ã©vidence les passages pertinents liÃ©s Ã  la rÃ©ponse 
- Utiliser une clÃ© OpenAI via saisie directe dans lâ€™interface

---


## ğŸ“¸ AperÃ§u de lâ€™application

![AperÃ§u de l'application](img1.gif)

---

## ğŸ“ Structure du projet
```bash
rag-pdf-app/
â”‚
â”œâ”€â”€ app.py                # Interface Streamlit
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils.py          # Fonctions utilitaires (PDF, nettoyage, chunking, highlight)
â”‚   â”œâ”€â”€ embeddings.py     # Gestion embeddings + VectorStore
â”‚   â”œâ”€â”€ llm.py            # Appels OpenAI + gÃ©nÃ©ration de prompts
â”‚
â””â”€â”€ README.md
```

---
## ğŸ› ï¸ Installation

### 1. Cloner le projet
```bash
git clone https://github.com/mochibane/rag-pdf-app.git
cd rag-pdf-app
```
### 2. CrÃ©er un environnement virtuel (recommandÃ©)
```bash
python -m venv venv
source venv/bin/activate        # Sur macOS/Linux
venv\Scripts\activate           # Sur Windows
```
### 3. Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```
### 4. Lancer lâ€™application 
```bash
streamlit run app.py
```
---
### L'application sera accessible sur **http://localhost:8501**




---
## âš ï¸ Limites de lâ€™application  

Cette application utilise lâ€™API **OpenAI**, ce qui entraÃ®ne deux limites principales :  

- ğŸ”’ **ConfidentialitÃ©** : les PDF et les questions sont envoyÃ©s aux serveurs dâ€™OpenAI. Ce nâ€™est pas idÃ©al pour des donnÃ©es sensibles.  
- â³ **Limite de tokens** : chaque appel Ã  lâ€™API a une limite de taille. Les PDF ou questions trop longs peuvent dÃ©passer cette limite.  

---

## ğŸ”® Solution alternative   

Une solution consiste Ã  utiliser un **modÃ¨le open-source** (comme Flan-T5, LLaMA, etc.) et Ã  le **fine-tuner en local** sur des tÃ¢ches et un contexte spÃ©cifiques.
Cela permet de garder les donnÃ©es **confidentielles** et dâ€™Ã©viter les limites de tokens dâ€™OpenAI. Cependant, cette approche demande Ã  la fois :  
- une **puissance de calcul importante** (GPU performants, serveurs adaptÃ©s),  
- et un **savoir-faire technique** pour rÃ©aliser le fine-tuning.  
 


